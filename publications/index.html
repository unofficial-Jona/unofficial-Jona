<!DOCTYPE html>
<html lang="en">
<head>
    <!-- Metadata and linking the stylesheet -->
    <link rel="stylesheet" href="../styles.css">
</head>
<body>
    <div class="main-wrapper"> 
        <div class="left-column">
            <!-- Insert your image path where the comment indicates -->
        
            <img src="../images/headshot.jpeg" alt="Headshot" class="headshot">
            
            <div class="static-info">
                <a href="mailto:jonathan.aechtner@web.de" class="contact-link" target="_blank">
                    <div class="contact-symbol" id="mail-symbol"></div>
                </a>
                <a href="https://github.com/unofficial-Jona" class="contact-link" target="_blank">
                    <div class="contact-symbol" id="github-symbol"></div>
                </a>
                <a href="https://www.linkedin.com/in/jonathan-aechtner-60bab921b/" class="contact-link" target="_blank">
                    <div class="contact-symbol" id="linkedin-symbol"></div>
                </a>
                <a href="https://twitter.com/unofficial_jona" class="contact-link" target="_blank">
                    <div class="contact-symbol" id="x-symbol"></div>
                </a>
            </div>
        </div>
        <div class="right-column">
            <!-- Navigation Bar -->
            <nav>
                <a href="../index.html"><b>Home</b></a>
                <a href="../cv/index.html"><b>CV</b></a>
                <a href="../projects/index.html"><b>Projects</b></a>
                <a href="../publications/index.html"><b>Publications</b></a>
            </nav>

            <!-- Main Content Area -->
            <div class="content">
                <!-- Left Column for Static Info -->
                

                <!-- Right Column for Dynamic/Main Content -->
                    <h1>Publications</h1>
                    <h2>Comparing User Perception of Explanations Developed with XAI Methods</h2>
                    <p>
                        Artificial Intelligence (AI) has gained notable momentum, culminating in the rise of intelligent machines that deliver unprecedented levels of performance in many application sectors across the field. In recent years, the sophistication of these systems has increased to an extent where almost no human intervention is required for their deployment. A crucial feature for the practical deployment of AI-powered systems in critical decision-making processes is the ability to understand how these systems derive their decisions. Accordingly, the AI community is confronted with the barrier of explaining the reasoning behind machine-made decisions. Paradigms underlying this problem fall within the field of eXplainable AI (XAI). Research in this field has introduced various methods to shed light into black box models such as deep neural networks. While local explanation methods explain the reasoning behind an output for a single decision, global explanations aim to describe the general behaviour of a model, i.e. for all decisions. This paper investigates users' perceptions of local and global explanations generated with popular XAI methods - LIME, SHAP, and PDP - by conducting a survey to find which of the explanations are preferred by different users. Meanwhile, two hypotheses are tested: first, explanations increase users' trust in a system, and second, AI novices prefer local over global explanations. The results show that explanations from PDP achieved the best user evaluation among the considered XAI methods.
                    </p>
                    <p> 
                    <a href="https://cris.maastrichtuniversity.nl/ws/portalfiles/portal/115371226/Wilbik_2022_Comparing_User_SaPsfacPon_of_ExplanaPons.pdf" target="_blank">Fulltext</a>
                    </p>

                    
                    
                    <!-- Your main content like "About Me" goes here -->
            </div>
        </div>
    </div>
    <footer>
        <p>&copy; 2023 Jonathan Aechtner. All rights reserved.</p>
    </footer>
</body>
</html>
